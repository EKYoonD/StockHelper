{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tBtc0H9-iwv-",
   "metadata": {
    "id": "tBtc0H9-iwv-"
   },
   "source": [
    "# 종목별 네이버 기사 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eIi0gfA1CHZR",
   "metadata": {
    "id": "eIi0gfA1CHZR"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "from sys import stdout\n",
    "\n",
    "def crawling_article(key_word):\n",
    "    Url = 'https://search.naver.com/search.naver?'\n",
    "    ds = ['2020.01.01', '2021.01.01']\n",
    "    #ds = ['2020.12.20', '2021.11.15']\n",
    "    de = ['2020.12.31', '2021.12.06']  # 두번째 날은 어제로 설정\n",
    "\n",
    "    params = {\n",
    "        \"where\" : 'news',\n",
    "        \"sm\": 'tab_pge',\n",
    "        \"query\": key_word,  # ★인코딩하지말고 넣어라★\n",
    "        \"sort\": '0',\n",
    "        \"photo\": '0',\n",
    "        \"field\": '0',\n",
    "        \"pd\": '3',\n",
    "        \"ds\": '2020.01.01',\n",
    "        \"de\" : '2020.12.31',\n",
    "        \"cluster_rank\": '10',\n",
    "        \"mynews\" : '1',\n",
    "        \"office_type\": '0',\n",
    "        \"office_section_code\": '0',\n",
    "        \"news_office_checked\" : '1032',\n",
    "        \"nso\" : r'so:r,p:from20210101to20211130,a:all',\n",
    "        \"start\" : '5000'\n",
    "    }\n",
    "\n",
    "    # 경향신문, 국민일보, 동아일보, 한겨례, 매일일보, 조선일보\n",
    "    news_code = ['1032', '1005', '1020', '1028', '2385', '1023']\n",
    "\n",
    "    # 크롤링 할 url 저장\n",
    "    urls = []\n",
    "    \n",
    "    page = 1\n",
    "    \n",
    "    for i in range(2):\n",
    "        # 날짜 설정\n",
    "        params['ds'] = ds[i]\n",
    "        params['de'] = de[i]\n",
    "        \n",
    "        for code in news_code:\n",
    "            params['news_office_checked'] = code\n",
    "            raw = requests.get(Url, headers={'User-Agent': 'Mozilla/5.0'}, params=params)\n",
    "\n",
    "            dom = BeautifulSoup(raw.text, \"html.parser\")\n",
    "\n",
    "            try:\n",
    "                a_tags = dom.select('#main_pack > div.api_sc_page_wrap > div > div > a')\n",
    "                last_page = int(a_tags[-1].text.strip())\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            for start in range(1, last_page * 10, 10):\n",
    "                params['start'] = start\n",
    "                raw = requests.get(Url, headers={'User-Agent': 'Mozilla/5.0'}, params=params)\n",
    "\n",
    "                dom = BeautifulSoup(raw.text, \"html.parser\")\n",
    "\n",
    "                lists = dom.select(\"#main_pack > section.sc_new.sp_nnews._prs_nws > div > div.group_news > ul > li\")\n",
    "\n",
    "                for l in lists:\n",
    "                    urls.append(l.select(\"div.news_wrap > div.news_area > div.news_info > div.info_group > a\")[-1]['href'])\n",
    "                \n",
    "                print('page:', page, '/  code:', code, '/  num:', start, '\\r', end='')\n",
    "                page += 1\n",
    "                time.sleep(1)\n",
    "\n",
    "    # 기사 총 몇 개 클롤링 하는지 보여주기\n",
    "    news_urls = [\n",
    "         url\n",
    "         for url in urls\n",
    "         if 'https://news.naver.com/' in url\n",
    "    ]\n",
    "    return news_urls, params\n",
    "\n",
    "def save_article(news_urls, params):\n",
    "    # 크롤링한 날짜, 제목, 본문 저장\n",
    "    news = []\n",
    "\n",
    "    i = 1 # 몇 번째 기사를 크롤링하는지 체크\n",
    "    \n",
    "    tot_sum = 0 \n",
    "    for url in tqdm(news_urls, desc = params['query']):\n",
    "        raw = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "        dom = BeautifulSoup(raw.text, \"html.parser\")\n",
    "\n",
    "        try:\n",
    "            title = dom.select_one('#articleTitle').text.strip()\n",
    "            date = dom.select_one('#main_content > div.article_header > div.article_info > div > span.t11').text.strip()[:10]\n",
    "        except Exception:\n",
    "            continue\n",
    "        \n",
    "        # <script> <style> 제거 (전처리)\n",
    "        for s in dom(['script', 'style', 'img']):\n",
    "            s.decompose()\n",
    "\n",
    "        # 뉴스본문 리턴\n",
    "        news_content = dom.find('div', attrs = {'id': 'articleBodyContents'})\n",
    "        # 뉴스본문에 대한 전처리\n",
    "        # 각 line 별로 strip(), 태그 제거\n",
    "        lines = [\n",
    "            line.strip()\n",
    "            for line in news_content.get_text().splitlines()\n",
    "        ]\n",
    "        news_content = ''.join(lines).replace('[경향신문]','')\n",
    "\n",
    "        dic = {\n",
    "            'title' : title,\n",
    "            'date' : date,\n",
    "            'content' : news_content\n",
    "        }\n",
    "        news.append(dic)\n",
    "        \n",
    "        i += 1\n",
    "        time.sleep(1)\n",
    "        tot_sum += i\n",
    "\n",
    "    df = pd.DataFrame(news)\n",
    "\n",
    "    base_path = r'../../dataset'\n",
    "    file_path = os.path.join(base_path, f\"{params['query']}_기사_크롤링_2020.01.01_{params['de']}.csv\")\n",
    "\n",
    "    df.to_csv(file_path, encoding='utf-8-sig')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c4c6107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 1 POSCO\n",
      "page: 21 /  code: 1023 /  num: 11 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "POSCO: 100%|█████████████████████████████████████████████████████████████████████████| 114/114 [02:34<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sys import stdout\n",
    "import time\n",
    "\n",
    "# 진섭\n",
    "keyword_list = [\n",
    " #'삼성SDI',\n",
    " #'삼성화재',\n",
    " #'두산중공업',\n",
    " #'CJ제일제당',\n",
    " #'강원랜드',\n",
    " #'GS건설',\n",
    " #'오리온',\n",
    " #'한국전력',\n",
    " #'현대글로비스',\n",
    " #'KT&G',\n",
    " #'SKC',\n",
    " #'삼성바이오로직스',\n",
    " #'LG유플러스',\n",
    " #'두산밥캣',\n",
    " #'유한양행',\n",
    " #'미래에셋증권',\n",
    " #'한국금융지주',\n",
    " #'삼성전기',\n",
    " #'삼성물산',\n",
    " #'SK',\n",
    " #'아모레퍼시픽',\n",
    " #'NH투자증권',\n",
    " #'셀트리온',\n",
    " #'GS리테일',\n",
    " #'삼성생명',\n",
    " #'삼성에스디에스',\n",
    " #'메리츠금융지주',\n",
    " #'현대모비스',\n",
    "    \n",
    "    #'GS',\n",
    "    #'S-Oil'\n",
    "    #'에스오일'\n",
    "    'POSCO'\n",
    "]\n",
    "\n",
    "news_urls = []\n",
    "\n",
    "cnt = 1\n",
    "\n",
    "# 키워드 리스트\n",
    "lst = keyword_list\n",
    "\n",
    "for keyword in lst:\n",
    "    print(cnt, \"/\", len(lst), keyword)\n",
    "    news_urls, params = crawling_article(keyword)\n",
    "    save_article(news_urls, params)\n",
    "    cnt += 1\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b96af407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b9ec78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성SDI\n",
      "삼성화재\n"
     ]
    }
   ],
   "source": [
    "for i in keyword_list[:2]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7963601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['삼성전자', 'SK하이닉스', 'NAVER', '삼성바이오로직스', '삼성전자우', '카카오', 'LG화학', '삼성SDI', '현대차', '기아', '카카오뱅크', '셀트리온', '카카오페이', 'POSCO', 'KB금융', '현대모비스', '크래프톤', '삼성물산', 'LG전자', '신한지주', 'SK이노베이션', 'SK', 'LG생활건강', 'SK바이오사이언스', '엔씨소프트', '한국전력', '삼성전기', '삼성생명', '하이브', 'HMM', '하나금융지주', 'LG', 'SK텔레콤', '삼성에스디에스', 'SK아이이테크놀로지', 'KT&G', '포스코케미칼', '두산중공업', '넷마블', '아모레퍼시픽', '대한항공', 'S-Oil', '현대중공업', '삼성화재', '우리금융지주', 'SK스퀘어', '고려아연', '기업은행', 'KT', 'LG디스플레이', '롯데케미칼', 'SK바이오팜', '한온시스템', 'SKC', '한국조선해양', '한화솔루션', 'LG이노텍', 'F&F', 'LG유플러스', '현대글로비스', '미래에셋증권', '현대제철', '코웨이', '현대건설', '맥쿼리인프라', '일진머티리얼즈', 'CJ제일제당', '금호석유', '에스디바이오센서', '강원랜드', 'KODEX 200', '한국타이어앤테크놀로지', '삼성중공업', '메리츠금융지주', '한국금융지주', '현대중공업지주', '삼성엔지니어링', '삼성증권', '유한양행', '두산밥캣', '이마트', '한진칼', '오리온', 'DB손해보험', '메리츠화재', '쌍용C&E', '삼성카드', 'NH투자증권', '아모레G', 'GS', '현대차2우B', '한미사이언스', '메리츠증권', '한솔케미칼', 'GS건설', '한국가스공사', '한전기술', 'GS리테일', '롯데지주', '한미약품']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63       CJ제일제당\n",
       "77       DB손해보험\n",
       "114          GS\n",
       "116        GS건설\n",
       "118       GS리테일\n",
       "         ...   \n",
       "7000     현대글로비스\n",
       "7005      현대모비스\n",
       "7027       현대제철\n",
       "7029    현대중공업지주\n",
       "7030        현대차\n",
       "Name: Name, Length: 86, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 주식 정보 가져오기\n",
    "import FinanceDataReader as fdr\n",
    "\n",
    "df = fdr.StockListing(\"KRX\")\n",
    "df\n",
    "\n",
    "# 다음 시가총액 TOP 100 읽어오기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 다음 시가총액 TOP 100\n",
    "url = \"https://finance.daum.net/api/trend/market_capitalization?page={}&perPage=30&fieldName=marketCap&order=desc&market=KOSPI&pagination=true\"\n",
    "\n",
    "headers={\n",
    "    \"User-Agent\" : \"Mozilla/5.0\",\n",
    "    \"referer\" : \"https://finance.daum.net/domestic/market_cap?market=KOSPI\"\n",
    "}\n",
    "\n",
    "stock_name = []\n",
    "for i in range(1, 5):\n",
    "    response = requests.get(url.format(i), headers=headers).json()  # json\n",
    "    data = response['data']\n",
    "\n",
    "    if i < 4:\n",
    "        for j in range(30):\n",
    "            stock_name.append(data[j]['name'])\n",
    "    else:\n",
    "        for j in range(10):\n",
    "            stock_name.append(data[j]['name'])\n",
    "            \n",
    "# stock_name.extend(['포스코', '케이티', '케이티앤지', '에스케이바이오팜', '금호석유화학','삼성화재해상보험', '쌍용씨앤이', '아모레퍼시픽그룹', '한국전력공사', '현대자동차'])\n",
    "print(stock_name)\n",
    "\n",
    "stock_name_df = pd.DataFrame(stock_name)\n",
    "\n",
    "# 시가총액 TOP 100 중 상장일이 2020-01-01 이전인 주식 정보 가져오기\n",
    "stock_df = df[df['Name'].isin(stock_name)]\n",
    "stock_df = stock_df[stock_df['ListingDate']<='2020-01-01']\n",
    "stock_df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bea1171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['일진머티리얼즈', 'LG화학', '메리츠화재', '삼성엔지니어링', '한국가스공사', '삼성중공업', '한화솔루션', '맥쿼리인프라', '카카오', 'DB손해보험', 'NAVER', '메리츠증권', '기아', '우리금융지주', '현대차', '이마트', '대한항공', '한솔케미칼', '아모레G', 'LG디스플레이', '한국타이어앤테크놀로지', '현대건설', '쌍용C&E', '한온시스템', '삼성전자', '금호석유', 'S-Oil', 'POSCO', 'GS', 'LG전자', '한진칼', 'LG생활건강', '고려아연', '한미사이언스', 'LG', '현대제철', '롯데케미칼', '포스코케미칼', '현대중공업지주', 'KT', 'SK하이닉스', '신한지주', 'LG이노텍', 'KB금융', '넷마블', '삼성카드', 'SK텔레콤', '한미약품', '엔씨소프트', '한국조선해양', 'HMM', '코웨이', '한전기술', '롯데지주', '기업은행', 'SK이노베이션', '하나금융지주', '삼성SDI', '삼성화재', '두산중공업', 'CJ제일제당', '강원랜드', 'GS건설', '오리온', '한국전력', '현대글로비스', 'KT&G', 'SKC', '삼성바이오로직스', 'LG유플러스', '두산밥캣', '유한양행', '미래에셋증권', '한국금융지주', '삼성전기', '삼성물산', 'SK', '아모레퍼시픽', 'NH투자증권', '셀트리온', 'GS리테일', '삼성생명', '삼성에스디에스', '메리츠금융지주', '현대모비스']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "stock_list = list(stock_df['Name'])\n",
    "stock_list.pop(stock_list.index('삼성증권'))\n",
    "random.shuffle(stock_list)  # 순서 바꿔주기\n",
    "print(stock_list)\n",
    "len(stock_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96c086a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['일진머티리얼즈',\n",
       " 'LG화학',\n",
       " '메리츠화재',\n",
       " '삼성엔지니어링',\n",
       " '한국가스공사',\n",
       " '삼성중공업',\n",
       " '한화솔루션',\n",
       " '맥쿼리인프라',\n",
       " '카카오',\n",
       " 'DB손해보험',\n",
       " 'NAVER',\n",
       " '메리츠증권',\n",
       " '기아',\n",
       " '우리금융지주',\n",
       " '현대차',\n",
       " '이마트',\n",
       " '대한항공',\n",
       " '한솔케미칼',\n",
       " '아모레G',\n",
       " 'LG디스플레이',\n",
       " '한국타이어앤테크놀로지',\n",
       " '현대건설',\n",
       " '쌍용C&E',\n",
       " '한온시스템',\n",
       " '삼성전자',\n",
       " '금호석유',\n",
       " 'S-Oil',\n",
       " 'POSCO',\n",
       " 'GS']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하병노\n",
    "stock_list[:29] \n",
    "\n",
    "'''\n",
    "['일진머티리얼즈',\n",
    " 'LG화학',\n",
    " '메리츠화재',\n",
    " '삼성엔지니어링',\n",
    " '한국가스공사',\n",
    " '삼성중공업',\n",
    " '한화솔루션',\n",
    " '맥쿼리인프라',\n",
    " '카카오',\n",
    " 'DB손해보험',\n",
    " 'NAVER',\n",
    " '메리츠증권',\n",
    " '기아',\n",
    " '우리금융지주',\n",
    " '현대차',\n",
    " '이마트',\n",
    " '대한항공',\n",
    " '한솔케미칼',\n",
    " '아모레G',\n",
    " 'LG디스플레이',\n",
    " '한국타이어앤테크놀로지',\n",
    " '현대건설',\n",
    " '쌍용C&E',\n",
    " '한온시스템',\n",
    " '삼성전자',\n",
    " '금호석유',\n",
    " 'S-Oil',\n",
    " 'POSCO',\n",
    " 'GS']\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e21db9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LG전자',\n",
       " '한진칼',\n",
       " 'LG생활건강',\n",
       " '고려아연',\n",
       " '한미사이언스',\n",
       " 'LG',\n",
       " '현대제철',\n",
       " '롯데케미칼',\n",
       " '포스코케미칼',\n",
       " '현대중공업지주',\n",
       " 'KT',\n",
       " 'SK하이닉스',\n",
       " '신한지주',\n",
       " 'LG이노텍',\n",
       " 'KB금융',\n",
       " '넷마블',\n",
       " '삼성카드',\n",
       " 'SK텔레콤',\n",
       " '한미약품',\n",
       " '엔씨소프트',\n",
       " '한국조선해양',\n",
       " 'HMM',\n",
       " '코웨이',\n",
       " '한전기술',\n",
       " '롯데지주',\n",
       " '기업은행',\n",
       " 'SK이노베이션',\n",
       " '하나금융지주']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 김영은\n",
    "stock_list[29:57]\n",
    "\n",
    "'''\n",
    "['LG전자',\n",
    " '한진칼',\n",
    " 'LG생활건강',\n",
    " '고려아연',\n",
    " '한미사이언스',\n",
    " 'LG',\n",
    " '현대제철',\n",
    " '롯데케미칼',\n",
    " '포스코케미칼',\n",
    " '현대중공업지주',\n",
    " 'KT',\n",
    " 'SK하이닉스',\n",
    " '신한지주',\n",
    " 'LG이노텍',\n",
    " 'KB금융',\n",
    " '넷마블',\n",
    " '삼성카드',\n",
    " 'SK텔레콤',\n",
    " '한미약품',\n",
    " '엔씨소프트',\n",
    " '한국조선해양',\n",
    " 'HMM',\n",
    " '코웨이',\n",
    " '한전기술',\n",
    " '롯데지주',\n",
    " '기업은행',\n",
    " 'SK이노베이션',\n",
    " '하나금융지주']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d9ce328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['삼성SDI',\n",
       " '삼성화재',\n",
       " '두산중공업',\n",
       " 'CJ제일제당',\n",
       " '강원랜드',\n",
       " 'GS건설',\n",
       " '오리온',\n",
       " '한국전력',\n",
       " '현대글로비스',\n",
       " 'KT&G',\n",
       " 'SKC',\n",
       " '삼성바이오로직스',\n",
       " 'LG유플러스',\n",
       " '두산밥캣',\n",
       " '유한양행',\n",
       " '미래에셋증권',\n",
       " '한국금융지주',\n",
       " '삼성전기',\n",
       " '삼성물산',\n",
       " 'SK',\n",
       " '아모레퍼시픽',\n",
       " 'NH투자증권',\n",
       " '셀트리온',\n",
       " 'GS리테일',\n",
       " '삼성생명',\n",
       " '삼성에스디에스',\n",
       " '메리츠금융지주',\n",
       " '현대모비스']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 김진섭\n",
    "stock_list[57:]\n",
    "\n",
    "'''\n",
    "['삼성SDI',\n",
    " '삼성화재',\n",
    " '두산중공업',\n",
    " 'CJ제일제당',\n",
    " '강원랜드',\n",
    " 'GS건설',\n",
    " '오리온',\n",
    " '한국전력',\n",
    " '현대글로비스',\n",
    " 'KT&G',\n",
    " 'SKC',\n",
    " '삼성바이오로직스',\n",
    " 'LG유플러스',\n",
    " '두산밥캣',\n",
    " '유한양행',\n",
    " '미래에셋증권',\n",
    " '한국금융지주',\n",
    " '삼성전기',\n",
    " '삼성물산',\n",
    " 'SK',\n",
    " '아모레퍼시픽',\n",
    " 'NH투자증권',\n",
    " '셀트리온',\n",
    " 'GS리테일',\n",
    " '삼성생명',\n",
    " '삼성에스디에스',\n",
    " '메리츠금융지주',\n",
    " '현대모비스']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917913e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "네이버 크롤링.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
