{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9b5971",
   "metadata": {},
   "source": [
    "---\n",
    "## [이용 가이드]\n",
    "\n",
    "#### 첫번째 셀 : 기본설정 및 크롤링\n",
    "- 사용자 설정 있음\n",
    "\n",
    "> `start_page` : 크롤링할 시작 페이지  \n",
    "> `resresh_unit` : 새로고침 단위 (320 페이지 이상 이동시 크롬 out of memory 발생  \n",
    "> `stop_page` : 크롤링할 마지막 페이지  \n",
    "> `file_name` : 저장할 파일명  \n",
    "- .기호 개당 1초를 의미 <- 사용자 정의 함수 delay(str, int)\n",
    "\n",
    "#### 두번째 셀 : 데이터 저장\n",
    "\n",
    "#### 세번째 셀 : 저장된 데이터 확인\n",
    "- 윈도우에서 인코딩 형식 디스매칭으로 글자 깨질 때 사용하기에 유용\n",
    "- 인덱스 번호와 게시물 번호 매칭하여 데이터 누락/중복 확인 가능\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3f4f5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프로그램 시작\n",
      "검색 옵션 설정....검색 완료\n",
      "데이터 추출 준비중...완료\n",
      "1 위치 -> 1 페이지 크롤링 완료\n",
      "현재 1 -> 2 click -> ..2 페이지 크롤링 완료\n",
      "현재 2 -> 3 click -> ..3 페이지 크롤링 완료\n",
      "현재 3 -> 4 click -> ..4 페이지 크롤링 완료\n",
      "현재 4 -> 5 click -> ..5 페이지 크롤링 완료\n",
      "현재 5 -> 6 click -> ..6 페이지 크롤링 완료\n",
      "현재 6 -> 7 click -> ..7 페이지 크롤링 완료\n",
      "현재 7 -> 8 click -> ..7 페이지 크롤링 완료\n",
      "현재 7 -> 9 click -> ..8 페이지 크롤링 완료\n",
      "현재 8 -> 10 click -> ..10 페이지 크롤링 완료\n",
      "현재 10 -> 다음 click -> ..11 페이지 크롤링 완료\n",
      "현재 11 -> 12 click -> ..12 페이지 크롤링 완료\n",
      "현재 12 -> 13 click -> ..13 페이지 크롤링 완료\n",
      "현재 13 -> 14 click -> ..14 페이지 크롤링 완료\n",
      "현재 14 -> 15 click -> ..15 페이지 크롤링 완료\n",
      "현재 15 -> 16 click -> ..16 페이지 크롤링 완료\n",
      "현재 16 -> 17 click -> ..17 페이지 크롤링 완료\n",
      "현재 17 -> 18 click -> ..18 페이지 크롤링 완료\n",
      "현재 18 -> 19 click -> ..19 페이지 크롤링 완료\n",
      "현재 19 -> 20 click -> ..20 페이지 크롤링 완료\n",
      "현재 20 -> 다음 click -> ..21 페이지 크롤링 완료\n",
      "현재 21 -> 22 click -> ..22 페이지 크롤링 완료\n",
      "현재 22 -> 23 click -> ..23 페이지 크롤링 완료\n",
      "현재 23 -> 24 click -> ..24 페이지 크롤링 완료\n",
      "현재 24 -> 25 click -> ..25 페이지 크롤링 완료\n",
      "현재 25 -> 26 click -> ..26 페이지 크롤링 완료\n",
      "현재 26 -> 27 click -> ..27 페이지 크롤링 완료\n",
      "현재 27 -> 28 click -> ..28 페이지 크롤링 완료\n",
      "현재 28 -> 29 click -> ..29 페이지 크롤링 완료\n",
      "현재 29 -> 30 click -> ..30 페이지 크롤링 완료\n",
      "현재 30 -> 다음 click -> ..31 페이지 크롤링 완료\n",
      "현재 31 -> 32 click -> ..32 페이지 크롤링 완료\n",
      "현재 32 -> 33 click -> ..33 페이지 크롤링 완료\n",
      "현재 33 -> 34 click -> ..34 페이지 크롤링 완료\n",
      "현재 34 -> 35 click -> ..35 페이지 크롤링 완료\n",
      "현재 35 -> 36 click -> ..36 페이지 크롤링 완료\n",
      "현재 36 -> 37 click -> ..37 페이지 크롤링 완료\n",
      "현재 37 -> 38 click -> ..38 페이지 크롤링 완료\n",
      "현재 38 -> 39 click -> ..39 페이지 크롤링 완료\n",
      "현재 39 -> 40 click -> ..40 페이지 크롤링 완료\n",
      "현재 40 -> 다음 click -> ..41 페이지 크롤링 완료\n",
      "현재 41 -> 42 click -> ..42 페이지 크롤링 완료\n",
      "현재 42 -> 43 click -> ..43 페이지 크롤링 완료\n",
      "현재 43 -> 44 click -> ..44 페이지 크롤링 완료\n",
      "현재 44 -> 45 click -> ..45 페이지 크롤링 완료\n",
      "현재 45 -> 46 click -> ..46 페이지 크롤링 완료\n",
      "현재 46 -> 47 click -> ..47 페이지 크롤링 완료\n",
      "현재 47 -> 48 click -> ..48 페이지 크롤링 완료\n",
      "현재 48 -> 49 click -> ..48 페이지 크롤링 완료\n",
      "현재 48 -> "
     ]
    },
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=96.0.4664.45)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9a2cebf48289>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[1;31m# 3.2.2. 크롤링할 페이지(target_page)인 다음 페이지로 이동\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{target_page.text} click'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" -> \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[0mtarget_page\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 크롤링할 페이지로 이동\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mdelay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mtext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;34m\"\"\"The text of the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_ELEMENT_TEXT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=96.0.4664.45)\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 셀 : 기본설정\n",
    "# 크롤링을 위해 사용자가 입력해야 되는 값\n",
    "start_page = 1    # 크롤링할 시작 페이지\n",
    "refresh_unit = 200   # 크롤링 후 새로고침할 단위\n",
    "stop_page = 1111   # 크롤링할 마지막 페이지\n",
    "file_name = 'patent_{date}_{first_page}_{last_page}.csv'  # 저장할 파일명\n",
    "\n",
    "# 메인\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from IPython.display import Image\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "\n",
    "# 함수 : 딜레이\n",
    "def delay(text, sec):\n",
    "    print(text, end=\"\")\n",
    "    for i in range(sec): print('.', end=\"\"); time.sleep(1)\n",
    "\n",
    "# 함수 : 사이트에서 제목/내용 크롤링\n",
    "current_page_css_selector = 'span.board_pager03 strong'\n",
    "def contentCrawling(current_page_css_selector = current_page_css_selector):\n",
    "    dom = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    patent_list = dom.select('.search_section article')\n",
    "    \n",
    "    current_page = driver.find_element_by_css_selector(current_page_css_selector).text\n",
    "\n",
    "    result = [\n",
    "            {\n",
    "                '제목': patent.select_one('.search_section_title h1 > a:nth-of-type(2)').text.strip(),\n",
    "                '내용': patent.select_one('.search_txt').text.strip()\n",
    "            }\n",
    "            for patent in patent_list\n",
    "    ]\n",
    "\n",
    "    return int(current_page), result   # (크롤링한 페이지, 크롤링 결과) 반환\n",
    "\n",
    "# 함수 : 저장할 파일 경로 찾기\n",
    "def findPath(file_name):\n",
    "    file_path = r'D:\\DevRoot\\StockHelper\\dataset'\n",
    "    file_name = file_name\n",
    "    try: \n",
    "        path = os.path.join(file_path, file_name)\n",
    "    except(Exception):\n",
    "        file_path = 'C:\\DeepLearning_Project\\StockHelper\\StockHelper\\dataset'\n",
    "        path = os.path.join(file_path, file_name)\n",
    "        \n",
    "    return path\n",
    "\n",
    "print('프로그램 시작')\n",
    "start = time.time()  # 시작 시간 저장\n",
    "result = []\n",
    "\n",
    "# 1. webdriver를 이용해 kipris 접속\n",
    "driver_path = r'D:\\DevRoot\\download\\chromedriver.exe'\n",
    "try: \n",
    "    driver = webdriver.Chrome(driver_path)\n",
    "except(Exception):\n",
    "    driver_path = r'C:\\DevRoot\\download\\chromedriver.exe'\n",
    "    driver = webdriver.Chrome(driver_path)\n",
    "\n",
    "for refreshed_num in range(1, math.ceil(stop_page / refresh_unit) + 1):\n",
    "    driver.get(\"http://kpat.kipris.or.kr/kpat/searchLogina.do?next=MainSearch\")\n",
    "    \n",
    "    # 크롤링 시작페이지 재설정\n",
    "    if refreshed_num != 1: start_page = refresh_unit * (refreshed_num - 1) + 1\n",
    "    \n",
    "    # 2. 검색 옵션 설정\n",
    "    delay('검색 옵션 설정', 4)\n",
    "\n",
    "    # 2.1. 행정상태 변경\n",
    "    # defalut 해제 <- '전체' 클릭\n",
    "    driver.find_element_by_css_selector('form#leftside .release_list > span:nth-of-type(1) > input').click()\n",
    "    # 원하는 checkbox만 선택 <- '등록' 클릭\n",
    "    driver.find_element_by_css_selector('form#leftside .release_list > span:nth-last-of-type(1) > input').click()\n",
    "\n",
    "    # 2.2. 기간을 검색어로 입력\n",
    "    today = datetime.today().strftime(\"%Y%m%d\")\n",
    "    decade = str(int(today) - int('00001000'))\n",
    "    driver.find_element_by_css_selector('.keyword').send_keys(f'GD=[{decade}~{today}]')\n",
    "    driver.find_element_by_css_selector('.input_btn img').click()\n",
    "\n",
    "    # 2.3. 90개씩 보기 선택\n",
    "    pageSel = 90   # 페이지당 게시물 개수 (30, 60, 90 중 택1)\n",
    "    select = Select(driver.find_element_by_id('opt28'))\n",
    "    select.select_by_value(str(pageSel))\n",
    "    driver.find_element_by_css_selector('#pageSel img').click()\n",
    "\n",
    "    print('검색 완료')\n",
    "\n",
    "    # 3. 데이터 추출\n",
    "    delay('데이터 추출 준비중', 3)\n",
    "    print('완료')\n",
    "\n",
    "    page_num = 'span.board_pager03 a:nth-last-of-type({0})'   # target_page 구할 때 이용\n",
    "\n",
    "    # 3.1. 첫 페이지 크롤링\n",
    "    current_page, data = contentCrawling()\n",
    "    if current_page == stop_page: break   # 실행종료\n",
    "    if current_page != start_page:   # 첫 페이지 찾기\n",
    "        delay('시작 페이지로 이동', 0)\n",
    "        while current_page < start_page:\n",
    "            if current_page // 10 < start_page // 10:\n",
    "                driver.find_element_by_css_selector(page_num.format(1)).click()\n",
    "                delay('', 2)\n",
    "                current_page = int(driver.find_element_by_css_selector(current_page_css_selector).text)\n",
    "                continue\n",
    "            for i in range(10, 0, -1):\n",
    "                driver.find_element_by_css_selector(page_num.format(i)).click()\n",
    "                delay('', 2)\n",
    "                current_page = int(driver.find_element_by_css_selector(current_page_css_selector).text)\n",
    "                if current_page == start_page: print('완료'); break\n",
    "    current_page, data = contentCrawling()\n",
    "    result.extend(data)\n",
    "    print(f'{current_page} 위치 -> {current_page} 페이지 크롤링 완료')\n",
    "\n",
    "    # 3.2. 페이지 이동하며 크롤링\n",
    "    while True:\n",
    "        # 실행 종료\n",
    "        if current_page >= stop_page: break\n",
    "        if current_page == refresh_unit * refreshed_num: break\n",
    "\n",
    "        for i in range(10, 0, -1):\n",
    "            if current_page >= stop_page: break\n",
    "            if current_page == refresh_unit * refreshed_num: break\n",
    "\n",
    "            # 3.2.1. 크롤링할 페이지가 현재 페이지의 다음 페이지인 지 확인\n",
    "            target_page = driver.find_element_by_css_selector(page_num.format(i))\n",
    "            if i != 1 and int(target_page.text) <= current_page: delay('', 1); continue \n",
    "\n",
    "            print(f'현재 {current_page}', end=\" -> \")\n",
    "            time.sleep(1)\n",
    "            # 3.2.2. 크롤링할 페이지(target_page)인 다음 페이지로 이동\n",
    "            print(f'{target_page.text} click', end=\" -> \")\n",
    "            target_page.click()  # 크롤링할 페이지로 이동\n",
    "            delay('', 2)        \n",
    "            while True:\n",
    "                click_page = driver.find_element_by_css_selector(current_page_css_selector).text\n",
    "    #             try: # (클릭해서 이동한) 현재 페이지(click_page)는 target_page\n",
    "    #                 click_page = driver.find_element_by_css_selector(current_page_css_selector).text\n",
    "    #             except KeyboardInterrupt or WebDriverException:\n",
    "    #                 print('Interrupted')\n",
    "    #                 try: sys.exit(0)\n",
    "    #                 except SystemExit: os._exit(0)\n",
    "    #                 finally:\n",
    "    #                     print('긁어온 데이터개수 :', len(result))\n",
    "    #                     print('소요시간 :', int(time.time() - start) / 60, '분')  # 현재시각 - 시작시간 = 실행 시간\n",
    "    #                     print('프로그램 종료')\n",
    "    #             except Exception:\n",
    "    #                 driver.refresh()   # 새로고침\n",
    "    #                 dealy('', 4)\n",
    "    #                 dom = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    #                 patent_list = dom.select('.search_section article')\n",
    "    #                 click_page = int(driver.find_element_by_css_selector(current_page_css_selector).text)\n",
    "\n",
    "                if current_page != click_page: break  # 페이지 이동 시 loop 탈출\n",
    "                delay(\"\", 2)  # 페이지 이동 안 하면 seelp()\n",
    "            # 3.2.3. 크롤링\n",
    "            current_page, data = contentCrawling()\n",
    "            result.extend(data)\n",
    "            # 3.2.4. 중간결과 반환\n",
    "            print(f'{current_page} 페이지 크롤링 완료')\n",
    "\n",
    "print('=' * 60)\n",
    "print('긁어온 데이터개수 :', len(result))\n",
    "print('소요시간 :', int(time.time() - start) / 60, '분')  # 현재시각 - 시작시간 = 실행 시간\n",
    "print('프로그램 종료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1565cbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 파일변환 완료: 2021-12-03 09:12:15\n",
      ">>> 저장위치: D:\\DevRoot\\StockHelper\\dataset\\patent_20211203_1_1111.0.csv\n"
     ]
    }
   ],
   "source": [
    "# 세번째 셀 : 데이터 저장\n",
    "# 데이터 저장 : list -> df -> csv 저장\n",
    "file_name = file_name.format(date=today, first_page=1, last_page=len(result) // 90)\n",
    "path = findPath(file_name)\n",
    "pd.DataFrame(result, index=range(1, len(result) + 1)).to_csv(path, encoding='utf-8')\n",
    "\n",
    "# 저장 결과 반환\n",
    "if os.path.isfile(path):\n",
    "    print('>>> 파일변환 완료:', datetime.today().strftime((\"%Y-%m-%d %H:%M:%S\")))\n",
    "    print('>>> 저장위치:', path)\n",
    "else: print('>>> 파일변환 실패')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0237bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네번째 셀 : 저장된 데이터 확인\n",
    "file_name = file_name.format(date=today)\n",
    "path = findPath(file_name)\n",
    "pd.read_csv(path).style.hide_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
